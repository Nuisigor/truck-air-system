{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Activities\n",
    "\n",
    "#### 1. What steps would you take to solve this problem? Please describe as completely and clearly as possible all the steps that you see as essential for solving the problem.\n",
    "**A:** I would do:\n",
    "- **Data Exploration**: Analyse the data creating visualizations and analyse the outliers, to understand what I can do with it.\n",
    "- **Data Treatment**: Treat the missing values using the most frequent value or the mean of the values for each column.\n",
    "- **Create a correlational map**: Create a correlational map to see the most relevant variables/columns.\n",
    "- **Reduce the dimensionality**: Use PCA to reduce the problem dimensionality.\n",
    "- **Train Regression**: Train simultaneous models as SGD, Linear Regression, Logistic Regression, etc... and get their results.\n",
    "    - **Create the train and test set**: Use the pareto principle to create the test set using 20% of the entire dataset.\n",
    "    - **Use GridSearchCV to select the best parameter**: Use GridSearch to train the models with different parameters using cross validation.\n",
    "- **Measure the results and Choose the best model**: Measure the MSE, RMSE and MAE of the models and choose the best one.\n",
    "- **Analyse the Impact on problem**: Calculate the impact for possible next billings.\n",
    "- **Create an presentation**: Presentate to the executive board.\n",
    "- ***If the solution is approved***:\n",
    "    - **Deploy the model in production**: Deploy the model for use.\n",
    "    - **Maintain and Monitoring**: Create a system to monitoring the model and a pipeline to retrain.\n",
    "\n",
    "#### 2. Which technical data science metric would you use to solve this challenge? Ex: absolute error, rmse, etc.\n",
    "**A:** I would use the f1-score and recall for classification models trying to avoid the false negative state, and for regression models the RMSE to measure the errors of the model to penalize big mistakes on the training, trying to get the best model for the problem. And for deciding the best approach between classification and regression, I would consider the nature of the target variable and the business objectives. If the target is a discrete class label indicating a state (e.g., whether a truck needs maintenance), classification metrics such as f1-score and recall are more appropriate. However, if the target is a continuous variable (e.g., the cost of maintenance or time until failure), regression metrics such as RMSE would be used to evaluate the models.\n",
    "\n",
    "#### 3. Which business metric would you use to solve the challenge?\n",
    "**A:** I would use the reduction in air system maintenance costs as the primary business metric. This metric directly reflects the financial impact of the model by measuring how much the model can reduce unnecessary maintenance costs and prevent costly breakdowns. \n",
    "\n",
    "#### 4. How do technical metrics relate to the business metrics?\n",
    "**A:** The metric tecniques indicate the precision for the models. A higher precision(least error) get the best predictions to indicate if a truck needs to go to maintaince, which can reduce the maintance cost avoiding not sending the trucks with defects.\n",
    "\n",
    "#### 5. What types of analyses would you like to perform on the customer database?\n",
    "**A:** Correlational analysis, and if possible, the time series analysis for getting insights to improve the decision when treating the data.\n",
    "\n",
    "#### 6. What techniques would you use to reduce the dimensionality of the problem?\n",
    "**A:** I would use the PCA to reduce dimensionality or an feature selector as Random Forest Importance to get the best features.\n",
    "\n",
    "#### 7. What techniques would you use to select variables for your predictive model?\n",
    "**A:** Analyse the correlation of the variables to get the best ones,or use Random Forest to get each variable importance to select the best ones.\n",
    "\n",
    "#### 8. What predictive models would you use or test for this problem? Please indicate at least 3.\n",
    "**A:** I would use the Linear Regression , SGD, Logistic Regression or Random Forest to understand the features importance.\n",
    "\n",
    "#### 9. How would you rate which of the trained models is the best?\n",
    "**A:** I would rate wich the technical metric such as RMSE using cross validation, and the expected cost reduce for the problem.\n",
    "\n",
    "#### 10. How would you explain the result of your model? Is it possible to know which variables are most important?\n",
    "**A:** To explain the results of my model, I would use feature importance for models like Random Forest and coefficients for linear models such as Linear Regression and Logistic Regression, create visualizations like bar charts to make these insights accessible to all stakeholders and provide example predictions; Yes, it is possible to identify the most important variables, as models like Random Forest and linear models offer ways to evaluate and rank each variable's importance.\n",
    "\n",
    "#### 11. How would you assess the financial impact of the proposed model?\n",
    "**A:** I would assess the financial impact of the proposed model by comparing maintenance costs before and after the model implementation. This would include cost reductions due to the prevention of undetected failures and fewer unnecessary maintenance activities.\n",
    "\n",
    "#### 12. What techniques would you use to perform the hyperparameter optimization of the chosen model?\n",
    "**A:** I would use techniques like Grid Search to explore different parameter combinations and identify those that provide the best performance and use cross-validation to ensure the results are robust and generalizable, selecting the hyperparameters that maximize the model performance metrics.\n",
    "\n",
    "#### 13. What risks or precautions would you present to the customer before putting this model into production?\n",
    "**A:** Before putting the model in production, I would present the risk of performance degradation over time, the importance data qualty, the need for continuous monitoring and model retraining and highlight the need for retrain if new data patterns and information emerge.\n",
    "\n",
    "#### 14. If your predictive model is approved, how would you put it into production?\n",
    "**A:** If the predictive model is approved, I would deploy it into production using an automated pipeline implementing the model on production environment, setting up monitoring routines to track real-time performance, and create processes for the continous collection of new data for future retraining.\n",
    "\n",
    "#### 15. If the model is in production, how would you monitor it?\n",
    "**A:** To monitor the model in production, I would establish key performance metrics, such as accuracy, recall, and other relevant metrics, and implement dashboards for real-time visualization, to audit periodically ensuring the model continues to provide valid and useful results.\n",
    "\n",
    "#### 16. If the model is in production, how would you know when to retrain it?\n",
    "**A:** To determine when to retrain the model in production, I would continuously monitor its performance metrics, if it indicates a drop in accuracy, an increase in false positives and negatives results I would suggest to retrain it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>na</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>na</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>na</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012</td>\n",
       "      <td>229790</td>\n",
       "      <td>405298</td>\n",
       "      <td>347188</td>\n",
       "      <td>286954</td>\n",
       "      <td>311560</td>\n",
       "      <td>433954</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       "0   neg   76698     na  2130706438    280      0      0      0      0      0   \n",
       "1   neg   33058     na           0     na      0      0      0      0      0   \n",
       "2   neg   41040     na         228    100      0      0      0      0      0   \n",
       "3   neg      12      0          70     66      0     10      0      0      0   \n",
       "4   neg   60874     na        1368    458      0      0      0      0      0   \n",
       "\n",
       "   ...   ee_002  ee_003  ee_004  ee_005  ee_006  ee_007  ee_008 ee_009 ef_000  \\\n",
       "0  ...  1240520  493384  721044  469792  339156  157956   73224      0      0   \n",
       "1  ...   421400  178064  293306  245416  133654   81140   97576   1500      0   \n",
       "2  ...   277378  159812  423992  409564  320746  158022   95128    514      0   \n",
       "3  ...      240      46      58      44      10       0       0      0      4   \n",
       "4  ...   622012  229790  405298  347188  286954  311560  433954   1218      0   \n",
       "\n",
       "  eg_000  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3     32  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('air_system_previous_years.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class         0\n",
      "aa_000        0\n",
      "ab_000    46329\n",
      "ac_000     3335\n",
      "ad_000    14861\n",
      "          ...  \n",
      "ee_007      671\n",
      "ee_008      671\n",
      "ee_009      671\n",
      "ef_000     2724\n",
      "eg_000     2723\n",
      "Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_counts = (df == 'na').sum()\n",
    "print(na_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'na' values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('na', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'pos' and 'neg' with 1 and 0.\n",
    "\n",
    "Imput values with the most frequent value for the column in the missin lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('neg', 0, inplace=True)\n",
    "df.replace('pos', 1, inplace=True)\n",
    "\n",
    "imputer  = SimpleImputer(strategy='most_frequent')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76698</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41040</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60874</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012</td>\n",
       "      <td>229790</td>\n",
       "      <td>405298</td>\n",
       "      <td>347188</td>\n",
       "      <td>286954</td>\n",
       "      <td>311560</td>\n",
       "      <td>433954</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       "0     0  76698      0  2130706438    280      0      0      0      0      0   \n",
       "1     0  33058      0           0      0      0      0      0      0      0   \n",
       "2     0  41040      0         228    100      0      0      0      0      0   \n",
       "3     0     12      0          70     66      0     10      0      0      0   \n",
       "4     0  60874      0        1368    458      0      0      0      0      0   \n",
       "\n",
       "   ...   ee_002  ee_003  ee_004  ee_005  ee_006  ee_007  ee_008 ee_009 ef_000  \\\n",
       "0  ...  1240520  493384  721044  469792  339156  157956   73224      0      0   \n",
       "1  ...   421400  178064  293306  245416  133654   81140   97576   1500      0   \n",
       "2  ...   277378  159812  423992  409564  320746  158022   95128    514      0   \n",
       "3  ...      240      46      58      44      10       0       0      0      4   \n",
       "4  ...   622012  229790  405298  347188  286954  311560  433954   1218      0   \n",
       "\n",
       "  eg_000  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3     32  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the columns correlation with the column 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df_imputed.corr()['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 1.0\n",
      "ci_000: 0.5500485913599936\n",
      "aa_000: 0.5369783925131034\n",
      "bt_000: 0.533963753708639\n",
      "bb_000: 0.5295008100476839\n",
      "bv_000: 0.5280560333237196\n",
      "bu_000: 0.5280560090906001\n",
      "cq_000: 0.5280559924814421\n",
      "aq_000: 0.5188414105610624\n",
      "bj_000: 0.5134648529917623\n",
      "cc_000: 0.5118862493439442\n",
      "ah_000: 0.5116309351809286\n",
      "an_000: 0.5106844611754808\n",
      "bg_000: 0.5092986651899168\n",
      "ao_000: 0.5072961420712778\n",
      "bx_000: 0.5046089291123149\n",
      "ap_000: 0.5029961600752952\n",
      "by_000: 0.5000872377036355\n",
      "ee_005: 0.4857230942244313\n",
      "bh_000: 0.48472307666818365\n",
      "dn_000: 0.481136717358398\n",
      "ba_004: 0.4776901910078724\n",
      "cn_004: 0.47371835477868135\n",
      "ck_000: 0.4640517182087593\n",
      "ba_003: 0.45934014514753435\n",
      "ba_005: 0.4514152236466959\n",
      "ag_005: 0.44817851080983434\n",
      "ee_002: 0.44396007810139426\n",
      "cs_005: 0.4419286525191903\n",
      "ba_001: 0.43765859465632967\n",
      "cs_004: 0.4375193685279318\n",
      "ag_003: 0.43305030605979666\n",
      "az_005: 0.4320135698926534\n",
      "ba_000: 0.4306455709457857\n",
      "ee_003: 0.42889850211051156\n",
      "ba_002: 0.4240190193280069\n",
      "bi_000: 0.41949249200635635\n",
      "ee_004: 0.4160957669315569\n",
      "ee_006: 0.4152619932869965\n",
      "ee_000: 0.4152453947913878\n",
      "ay_008: 0.40980230256696804\n",
      "cn_003: 0.4060340434330747\n",
      "ba_006: 0.39403539012381056\n",
      "cs_003: 0.3916487582733245\n",
      "cn_001: 0.3906803644662862\n",
      "cs_002: 0.37241227110681624\n",
      "ag_004: 0.3716224837308876\n",
      "am_0: 0.37159026487281577\n",
      "cn_005: 0.3711086306534804\n",
      "ag_006: 0.36834794713121766\n",
      "cn_002: 0.3677922793655176\n",
      "al_000: 0.36545199897228886\n",
      "ee_001: 0.3636579829600911\n",
      "az_004: 0.35875227218578104\n",
      "cs_000: 0.3531326646578861\n",
      "ag_002: 0.33995567821438133\n",
      "ed_000: 0.3390038339612119\n",
      "ba_007: 0.3362646895655003\n",
      "dt_000: 0.3102274951858861\n",
      "cm_000: 0.3101667222474641\n",
      "ds_000: 0.31003085944382924\n",
      "cs_001: 0.3072075303340185\n",
      "cj_000: 0.3068708854920383\n",
      "ay_007: 0.3028040687802423\n",
      "ec_00: 0.2977263331052941\n",
      "br_000: 0.2742496359325492\n",
      "dd_000: 0.27133477489300556\n",
      "bq_000: 0.26385640546479017\n",
      "az_001: 0.2638043878275052\n",
      "do_000: 0.2593900640392685\n",
      "bp_000: 0.24513223493393613\n",
      "ba_008: 0.24280663530416494\n",
      "ag_007: 0.24191004312131703\n",
      "dp_000: 0.2409819711278993\n",
      "ee_008: 0.2354014101091674\n",
      "ay_006: 0.2322010679762987\n",
      "cn_000: 0.23182692355941958\n",
      "cs_006: 0.2296713009256175\n",
      "ba_009: 0.22417930927016463\n",
      "bo_000: 0.2226404131642737\n",
      "ay_005: 0.21211883150516272\n",
      "dc_000: 0.2112123607250298\n",
      "cv_000: 0.2100099511801215\n",
      "cx_000: 0.20378042417447498\n",
      "az_007: 0.20338294907294188\n",
      "az_000: 0.20191029739557806\n",
      "cn_006: 0.19517062727206874\n",
      "bn_000: 0.19286219930987866\n",
      "ag_001: 0.19108385741369863\n",
      "ay_003: 0.19057701035926938\n",
      "cn_007: 0.18751260095381397\n",
      "de_000: 0.18569959984159096\n",
      "cn_008: 0.18486872032651927\n",
      "dv_000: 0.18436413565108917\n",
      "bc_000: 0.18070842309778348\n",
      "ce_000: 0.17955801052886466\n",
      "ay_004: 0.17955130156363894\n",
      "bs_000: 0.17839369337020822\n",
      "bd_000: 0.1742767198191222\n",
      "bf_000: 0.16847484265660956\n",
      "ay_002: 0.16515809147283952\n",
      "di_000: 0.16275760372486744\n",
      "cl_000: 0.1613673733448453\n",
      "ee_007: 0.1602956465742909\n",
      "ay_000: 0.1567008312069885\n",
      "bz_000: 0.15190011183066898\n",
      "bm_000: 0.15121612533308845\n",
      "dr_000: 0.15055662351338123\n",
      "du_000: 0.1491551355360835\n",
      "eb_000: 0.1482303428957906\n",
      "az_002: 0.14589380005921018\n",
      "ar_000: 0.14265057576507703\n",
      "dx_000: 0.14002128924550825\n",
      "at_000: 0.13604238073614455\n",
      "dg_000: 0.1319075442171613\n",
      "av_000: 0.12094470987206675\n",
      "az_003: 0.11951354892916738\n",
      "ai_000: 0.1182730875498226\n",
      "be_000: 0.11773138599296716\n",
      "ee_009: 0.1159251610189069\n",
      "ag_008: 0.11300610195605071\n",
      "ay_001: 0.11163654580847723\n",
      "cn_009: 0.10619239241991313\n",
      "ax_000: 0.10553149357731685\n",
      "dy_000: 0.10301590999044266\n",
      "au_000: 0.0911242484748042\n",
      "az_006: 0.08865666823934192\n",
      "df_000: 0.08760712127434754\n",
      "dq_000: 0.0853657249165104\n",
      "bl_000: 0.0809692925650325\n",
      "cg_000: 0.07690051898271573\n",
      "ag_009: 0.0720813787568168\n",
      "cu_000: 0.07189952631030415\n",
      "cb_000: 0.05826683726356262\n",
      "cs_007: 0.057267423562719785\n",
      "bk_000: 0.05504837231183025\n",
      "ac_000: 0.05099634473091555\n",
      "cy_000: 0.050498071099301746\n",
      "cp_000: 0.049611357418155984\n",
      "az_008: 0.04626872508107541\n",
      "as_000: 0.04313314726654638\n",
      "ay_009: 0.04234899646046858\n",
      "cr_000: 0.031686598228626656\n",
      "ct_000: 0.031206891370399788\n",
      "dz_000: 0.030981821732564477\n",
      "dh_000: 0.03007049537255984\n",
      "ca_000: 0.028452251698775275\n",
      "cz_000: 0.02517043249651681\n",
      "aj_000: 0.02387155801507678\n",
      "db_000: 0.016747387168158583\n",
      "af_000: 0.01624992251759167\n",
      "ab_000: 0.015084381201274637\n",
      "ef_000: 0.013649619524194669\n",
      "eg_000: 0.012809195397490345\n",
      "ag_000: 0.012352590919049406\n",
      "dk_000: 0.011874572526986297\n",
      "ak_000: 0.011752894095135578\n",
      "ch_000: 0.008404358460549414\n",
      "ea_000: 0.0073716553556385815\n",
      "ae_000: 0.005541072015891316\n",
      "dl_000: 0.003224027785469463\n",
      "da_000: 0.002973651121296902\n",
      "dm_000: 0.0028389017145653062\n",
      "az_009: 0.002535488160837462\n",
      "dj_000: 0.0010982437210427397\n",
      "cs_009: 0.0005395579756292038\n",
      "ad_000: 0.0005297612434709947\n",
      "cf_000: 0.0005297447281050938\n",
      "co_000: 0.0005270699499291449\n",
      "cs_008: 7.172340641388981e-05\n",
      "cd_000: nan\n"
     ]
    }
   ],
   "source": [
    "correlation = correlation.abs().sort_values(ascending=False)\n",
    "for index, value in zip(correlation.index, correlation.values):\n",
    "    print(f'{index}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ci_000',\n",
       " 'aa_000',\n",
       " 'bt_000',\n",
       " 'bb_000',\n",
       " 'bv_000',\n",
       " 'bu_000',\n",
       " 'cq_000',\n",
       " 'aq_000',\n",
       " 'bj_000',\n",
       " 'cc_000',\n",
       " 'ah_000',\n",
       " 'an_000',\n",
       " 'bg_000',\n",
       " 'ao_000',\n",
       " 'bx_000',\n",
       " 'ap_000',\n",
       " 'by_000',\n",
       " 'ee_005',\n",
       " 'bh_000',\n",
       " 'dn_000',\n",
       " 'ba_004',\n",
       " 'cn_004',\n",
       " 'ck_000',\n",
       " 'ba_003',\n",
       " 'ba_005',\n",
       " 'ag_005',\n",
       " 'ee_002',\n",
       " 'cs_005',\n",
       " 'ba_001',\n",
       " 'cs_004',\n",
       " 'ag_003',\n",
       " 'az_005',\n",
       " 'ba_000',\n",
       " 'ee_003',\n",
       " 'ba_002',\n",
       " 'bi_000',\n",
       " 'ee_004',\n",
       " 'ee_006',\n",
       " 'ee_000',\n",
       " 'ay_008',\n",
       " 'cn_003',\n",
       " 'ba_006',\n",
       " 'cs_003',\n",
       " 'cn_001',\n",
       " 'cs_002',\n",
       " 'ag_004',\n",
       " 'am_0',\n",
       " 'cn_005',\n",
       " 'ag_006',\n",
       " 'cn_002',\n",
       " 'al_000',\n",
       " 'ee_001',\n",
       " 'az_004',\n",
       " 'cs_000']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_correlated_columns = correlation[correlation >= 0.35].index\n",
    "most_correlated_columns = [col for col in most_correlated_columns if col != 'class']\n",
    "most_correlated_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating labels from attributes and applying StandardScaler for data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ci_000</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>bt_000</th>\n",
       "      <th>bb_000</th>\n",
       "      <th>bv_000</th>\n",
       "      <th>bu_000</th>\n",
       "      <th>cq_000</th>\n",
       "      <th>aq_000</th>\n",
       "      <th>bj_000</th>\n",
       "      <th>cc_000</th>\n",
       "      <th>...</th>\n",
       "      <th>cs_002</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>am_0</th>\n",
       "      <th>cn_005</th>\n",
       "      <th>ag_006</th>\n",
       "      <th>cn_002</th>\n",
       "      <th>al_000</th>\n",
       "      <th>ee_001</th>\n",
       "      <th>az_004</th>\n",
       "      <th>cs_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214020</td>\n",
       "      <td>0.119381</td>\n",
       "      <td>0.120095</td>\n",
       "      <td>0.205083</td>\n",
       "      <td>0.206969</td>\n",
       "      <td>0.206969</td>\n",
       "      <td>0.206969</td>\n",
       "      <td>0.552090</td>\n",
       "      <td>0.162485</td>\n",
       "      <td>0.273471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026344</td>\n",
       "      <td>-0.167256</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>0.520355</td>\n",
       "      <td>-0.149090</td>\n",
       "      <td>-0.109015</td>\n",
       "      <td>0.364410</td>\n",
       "      <td>-0.202987</td>\n",
       "      <td>0.492316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.140409</td>\n",
       "      <td>-0.180697</td>\n",
       "      <td>-0.180302</td>\n",
       "      <td>-0.076662</td>\n",
       "      <td>-0.075562</td>\n",
       "      <td>-0.075562</td>\n",
       "      <td>-0.075562</td>\n",
       "      <td>-0.079170</td>\n",
       "      <td>-0.062298</td>\n",
       "      <td>-0.069599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058965</td>\n",
       "      <td>-0.175301</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>-0.149055</td>\n",
       "      <td>-0.109015</td>\n",
       "      <td>0.019181</td>\n",
       "      <td>-0.108156</td>\n",
       "      <td>0.072159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.136617</td>\n",
       "      <td>-0.125811</td>\n",
       "      <td>-0.125354</td>\n",
       "      <td>-0.166468</td>\n",
       "      <td>-0.165619</td>\n",
       "      <td>-0.165619</td>\n",
       "      <td>-0.165619</td>\n",
       "      <td>-0.226223</td>\n",
       "      <td>-0.201648</td>\n",
       "      <td>-0.110265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148707</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.071220</td>\n",
       "      <td>0.062728</td>\n",
       "      <td>-0.149090</td>\n",
       "      <td>-0.109015</td>\n",
       "      <td>-0.125823</td>\n",
       "      <td>0.084359</td>\n",
       "      <td>-0.178611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414981</td>\n",
       "      <td>-0.407928</td>\n",
       "      <td>-0.407764</td>\n",
       "      <td>-0.411136</td>\n",
       "      <td>-0.410971</td>\n",
       "      <td>-0.410971</td>\n",
       "      <td>-0.410971</td>\n",
       "      <td>-0.347690</td>\n",
       "      <td>-0.277063</td>\n",
       "      <td>-0.381834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195306</td>\n",
       "      <td>-0.182094</td>\n",
       "      <td>-0.104620</td>\n",
       "      <td>-0.423308</td>\n",
       "      <td>-0.420782</td>\n",
       "      <td>-0.146708</td>\n",
       "      <td>-0.107819</td>\n",
       "      <td>-0.302519</td>\n",
       "      <td>-0.350741</td>\n",
       "      <td>-0.427045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012486</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>-0.017370</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>0.089865</td>\n",
       "      <td>-0.058323</td>\n",
       "      <td>0.037215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128370</td>\n",
       "      <td>-0.164503</td>\n",
       "      <td>-0.109228</td>\n",
       "      <td>-0.106301</td>\n",
       "      <td>0.041390</td>\n",
       "      <td>-0.148757</td>\n",
       "      <td>-0.109015</td>\n",
       "      <td>0.050497</td>\n",
       "      <td>-0.343507</td>\n",
       "      <td>-0.143760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ci_000    aa_000    bt_000    bb_000    bv_000    bu_000    cq_000  \\\n",
       "0  0.214020  0.119381  0.120095  0.205083  0.206969  0.206969  0.206969   \n",
       "1 -0.140409 -0.180697 -0.180302 -0.076662 -0.075562 -0.075562 -0.075562   \n",
       "2 -0.136617 -0.125811 -0.125354 -0.166468 -0.165619 -0.165619 -0.165619   \n",
       "3 -0.414981 -0.407928 -0.407764 -0.411136 -0.410971 -0.410971 -0.410971   \n",
       "4  0.012486  0.010572  0.011171 -0.017370 -0.016105 -0.016105 -0.016105   \n",
       "\n",
       "     aq_000    bj_000    cc_000  ...    cs_002    ag_004      am_0    cn_005  \\\n",
       "0  0.552090  0.162485  0.273471  ...  0.026344 -0.167256 -0.109228  0.613924   \n",
       "1 -0.079170 -0.062298 -0.069599  ... -0.058965 -0.175301 -0.109228 -0.012450   \n",
       "2 -0.226223 -0.201648 -0.110265  ... -0.148707 -0.182333 -0.109228 -0.071220   \n",
       "3 -0.347690 -0.277063 -0.381834  ... -0.195306 -0.182094 -0.104620 -0.423308   \n",
       "4  0.089865 -0.058323  0.037215  ... -0.128370 -0.164503 -0.109228 -0.106301   \n",
       "\n",
       "     ag_006    cn_002    al_000    ee_001    az_004    cs_000  \n",
       "0  0.520355 -0.149090 -0.109015  0.364410 -0.202987  0.492316  \n",
       "1  0.020950 -0.149055 -0.109015  0.019181 -0.108156  0.072159  \n",
       "2  0.062728 -0.149090 -0.109015 -0.125823  0.084359 -0.178611  \n",
       "3 -0.420782 -0.146708 -0.107819 -0.302519 -0.350741 -0.427045  \n",
       "4  0.041390 -0.148757 -0.109015  0.050497 -0.343507 -0.143760  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_imputed.drop('class', axis=1)[most_correlated_columns].astype(float)\n",
    "y = df_imputed['class'].astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.628922</td>\n",
       "      <td>-1.345564</td>\n",
       "      <td>-0.213654</td>\n",
       "      <td>-0.403473</td>\n",
       "      <td>0.384583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.585390</td>\n",
       "      <td>-0.329233</td>\n",
       "      <td>0.078444</td>\n",
       "      <td>0.164999</td>\n",
       "      <td>0.075628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.900251</td>\n",
       "      <td>-0.097231</td>\n",
       "      <td>-0.217269</td>\n",
       "      <td>-0.209744</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.516930</td>\n",
       "      <td>0.284735</td>\n",
       "      <td>-0.070657</td>\n",
       "      <td>0.158977</td>\n",
       "      <td>0.069612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.032869</td>\n",
       "      <td>-0.273508</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>-0.214371</td>\n",
       "      <td>-0.219891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pca_0     pca_1     pca_2     pca_3     pca_4\n",
       "0  1.628922 -1.345564 -0.213654 -0.403473  0.384583\n",
       "1 -0.585390 -0.329233  0.078444  0.164999  0.075628\n",
       "2 -0.900251 -0.097231 -0.217269 -0.209744  0.003336\n",
       "3 -2.516930  0.284735 -0.070657  0.158977  0.069612\n",
       "4 -0.032869 -0.273508  0.079855 -0.214371 -0.219891"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X_scaled), columns=[f'pca_{i}' for i in range(5)], index=X_scaled.index)\n",
    "X_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Basic Models for Initial Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating training and test data using Pareto distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some basic models to visualize the MSE and RMSE of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "log_reg = LogisticRegression(max_iter=200, solver='lbfgs')\n",
    "log_reg.fit(X_train, y_train)\n",
    "lin_reg, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.011394879760092437\n",
      "Linear Regression RMSE: 0.10674680210710032\n",
      "Logistic Regression MSE: 0.01525\n",
      "Logistic Regression RMSE: 0.1234908903522847\n"
     ]
    }
   ],
   "source": [
    "lin_reg_pred = lin_reg.predict(X_test)\n",
    "lin_reg_mse = mean_squared_error(y_test, lin_reg_pred)\n",
    "print(f'Linear Regression MSE: {lin_reg_mse}')\n",
    "print(f'Linear Regression RMSE: {np.sqrt(lin_reg_mse)}')\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "log_reg_mse = mean_squared_error(y_test, log_reg_pred)\n",
    "print(f'Logistic Regression MSE: {log_reg_mse}')\n",
    "print(f'Logistic Regression RMSE: {np.sqrt(log_reg_mse)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating set to validate '*air_system_present_year.csv*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('air_system_present_year.csv')\n",
    "\n",
    "new_df = new_df.replace('na', np.nan)\n",
    "new_df = new_df.replace('neg', 0)\n",
    "new_df = new_df.replace('pos', 1)\n",
    "\n",
    "new_df_imputed = pd.DataFrame(imputer.transform(new_df), columns=new_df.columns, index=new_df.index)\n",
    "\n",
    "new_X = new_df_imputed.drop('class', axis=1)[most_correlated_columns].astype(float)\n",
    "new_y = new_df_imputed['class'].astype(int)\n",
    "new_X_scaled = pd.DataFrame(scaler.transform(new_X), columns=new_X.columns, index=new_X.index)\n",
    "new_X_pca = pd.DataFrame(pca.transform(new_X_scaled), columns=[f'pca_{i}' for i in range(5)], index=new_X_scaled.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating with '*air_system_present_year.csv*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression MSE: 0.01825\n",
      "Logistic Regression RMSE: 0.13509256086106294\n"
     ]
    }
   ],
   "source": [
    "log_reg_pred = log_reg.predict(new_X_pca)\n",
    "log_reg_mse = mean_squared_error(new_y, log_reg_pred)\n",
    "log_reg_rmse = np.sqrt(log_reg_mse)\n",
    "print(f'Logistic Regression MSE: {log_reg_mse}')\n",
    "print(f'Logistic Regression RMSE: {log_reg_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the pipeline to treat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "most_correlated_columns = ['ci_000','aa_000','bt_000','bb_000','bv_000','bu_000','cq_000','aq_000','bj_000','cc_000','ah_000','an_000','bg_000','ao_000','bx_000','ap_000','by_000','ee_005','bh_000','dn_000','ba_004','cn_004','ck_000','ba_003','ba_005','ag_005','ee_002','cs_005','ba_001','cs_004','ag_003','az_005','ba_000','ee_003','ba_002','bi_000','ee_004','ee_006','ee_000','ay_008','cn_003','ba_006','cs_003','cn_001','cs_002','ag_004','am_0','cn_005','ag_006','cn_002','al_000','ee_001','az_004','cs_000']\n",
    "\n",
    "class DataFrameMissingValuesReplacer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.replace('na', np.nan)\n",
    "        return X\n",
    "    \n",
    "class DataFrameColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selector', DataFrameColumnSelector(most_correlated_columns)),\n",
    "    ('replacer', DataFrameMissingValuesReplacer()),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('air_system_previous_years.csv')\n",
    "X = dff.drop('class', axis=1)\n",
    "y = dff['class'].replace('neg', 0).replace('pos', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting and transforming the columns with the created pipeline, and saving the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X)\n",
    "X_transformed = pd.DataFrame(pipeline.transform(X), columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], index=X.index)\n",
    "joblib.dump(pipeline, 'pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to select the best model, using for parameters, the train and test set, number of jobs to do the train, the quantity of cross validation folds and the model to be trained.\n",
    "\n",
    "This function trains the model on combined training and validation sets, evaluating performance across different subsets defined by the cross-validation strategy, evaluating each using the custom train_regressor function that computes the root mean squared error for each model configuration. The model with the lowest RMSE is selected as the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(regressor, X_train, X_val, y_train, y_val, params):\n",
    "    reg = regressor(**params)\n",
    "    reg.fit(X_train, y_train)\n",
    "    predictions = reg.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def select_best_model(regressor, X_train, y_train, params ={}, cv_folds=10, n_jobs=4):\n",
    "    clf = GridSearchCV(regressor(), params, cv=cv_folds, scoring='neg_root_mean_squared_error', n_jobs=n_jobs)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_params = clf.best_params_\n",
    "    best_score = -clf.best_score_  # Convert to positive as scoring is negative RMSE\n",
    "    best_estimator = clf.best_estimator_\n",
    "    return best_estimator, best_params, best_score\n",
    "\n",
    "def do_cv(regressor, X, y, cv_splits=5, param_cv_folds=None, n_jobs=8, params={}):\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "    rmses = []\n",
    "    trained_regressors = []\n",
    "    best_aprameters = []\n",
    "    pgb = tqdm(total=cv_splits, desc='Folds evaluated')\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "            \n",
    "        reg, best_params, _ = select_best_model(regressor, X_train, y_train, n_jobs=n_jobs, cv_folds=param_cv_folds, params=params)\n",
    "        predictions = reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        rmses.append(rmse)\n",
    "        best_aprameters.append(best_params)\n",
    "        trained_regressors.append(reg)\n",
    "        pgb.update(1)\n",
    "\n",
    "    pgb.close()\n",
    "    return rmses, trained_regressors, best_aprameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the parameters for training each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {}  # Linear Regression has no parameters for tuning in this simple form\n",
    "params_log_reg = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization strengths\n",
    "    'solver': ['liblinear', 'lbfgs']  # Solvers\n",
    "}\n",
    "params_sgd = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Types of penalties for regularization\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularization strength\n",
    "    'max_iter': [1000],  # Maximum number of passes over the data\n",
    "    'tol': [1e-3],  # The stopping criterion\n",
    "    'eta0': [0.01, 0.1],  # Initial learning rate for the 'constant' or 'adaptive' schedules\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],  # Learning rate schedule\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation and calculate the average RMSE for linear regression, logistic regression and sgd regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds evaluated: 100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n",
      "Folds evaluated: 100%|██████████| 10/10 [00:13<00:00,  1.31s/it]\n",
      "Folds evaluated: 100%|██████████| 10/10 [03:07<00:00, 18.77s/it]\n"
     ]
    }
   ],
   "source": [
    "linear_rmse, linear_trained_models, _ = do_cv(LinearRegression, X_transformed, y, cv_splits=10, params=params_lr, n_jobs=16)\n",
    "log_reg_rmse, log_reg_trained_models, log_reg_params = do_cv(LogisticRegression, X_transformed, y, cv_splits=10, params=params_log_reg, n_jobs=8)\n",
    "sgd_rmse, sgd_trained_models, sgd_params = do_cv( SGDRegressor, X_transformed, y, cv_splits=10, params=params_sgd, n_jobs=8)\n",
    "\n",
    "linear_avg_rmse = np.mean(linear_rmse)\n",
    "log_reg_avg_rmse = np.mean(log_reg_rmse)\n",
    "sgd_avg_rmse = np.mean(sgd_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Linear Regression: 0.10522179176922435\n",
      "Average RMSE for Logistic Regression: 0.12233264194155857\n",
      "Average RMSE for SGD Regressor: 0.10521052481812418\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average RMSE for Linear Regression: {linear_avg_rmse}\")\n",
    "print(f\"Average RMSE for Logistic Regression: {log_reg_avg_rmse}\")\n",
    "print(f\"Average RMSE for SGD Regressor: {sgd_avg_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the validation data and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validate = pd.read_csv('air_system_present_year.csv')\n",
    "X_validate = df_validate.drop('class', axis=1)\n",
    "y_validate = df_validate['class'].replace('neg', 0).replace('pos', 1)\n",
    "X_validate_transformed = pd.DataFrame(pipeline.transform(X_validate), columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], index=X_validate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for Linear Regression: 0.11794454036393962\n",
      "Average RMSE for Logistic Regression: 0.13420710713040307\n",
      "Average RMSE for SGD Regressor: 0.11796058367163602\n"
     ]
    }
   ],
   "source": [
    "linear_rmse = []\n",
    "log_reg_rmse = []\n",
    "sgd_rmse = []\n",
    "\n",
    "for i in range(10):\n",
    "    linear_predictions = linear_trained_models[i].predict(X_validate_transformed)\n",
    "    log_reg_predictions = log_reg_trained_models[i].predict(X_validate_transformed)\n",
    "    sgd_predictions = sgd_trained_models[i].predict(X_validate_transformed)\n",
    "    \n",
    "    linear_rmse.append(np.sqrt(mean_squared_error(y_validate, linear_predictions)))\n",
    "    log_reg_rmse.append(np.sqrt(mean_squared_error(y_validate, log_reg_predictions)))\n",
    "    sgd_rmse.append(np.sqrt(mean_squared_error(y_validate, sgd_predictions)))\n",
    "\n",
    "linear_avg_rmse = np.mean(linear_rmse)\n",
    "log_reg_avg_rmse = np.mean(log_reg_rmse)\n",
    "sgd_avg_rmse = np.mean(sgd_rmse)\n",
    "\n",
    "print(f\"Average RMSE for Linear Regression: {linear_avg_rmse}\")\n",
    "print(f\"Average RMSE for Logistic Regression: {log_reg_avg_rmse}\")\n",
    "print(f\"Average RMSE for SGD Regressor: {sgd_avg_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the best trained model for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_model = linear_trained_models[np.argmin(linear_rmse)]\n",
    "best_log_reg_model = log_reg_trained_models[np.argmin(log_reg_rmse)]\n",
    "best_sgd_model = sgd_trained_models[np.argmin(sgd_rmse)]\n",
    "joblib.dump(best_linear_model, 'models/best_linear_model.pkl')\n",
    "joblib.dump(best_log_reg_model, 'models/best_log_reg_model.pkl')\n",
    "joblib.dump(best_sgd_model, 'models/best_sgd_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the average RMSE for the models, the SGD was the best one, so we'll take it to make the analysis of costs in present year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_sgd_model.predict(X_validate_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the threshold of 0.2, 0.3, 0.4 and 0.5 in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>245.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  false_negatives  false_positives  true_positives\n",
       "0        0.1             37.0            455.0           338.0\n",
       "1        0.2            103.0            204.0           272.0\n",
       "2        0.3            187.0            109.0           188.0\n",
       "3        0.4            245.0             40.0           130.0\n",
       "4        0.5            300.0             20.0            75.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'threshold': [],\n",
    "    'false_negatives': [],\n",
    "    'false_positives': [],\n",
    "    'true_positives': []\n",
    "})\n",
    "\n",
    "for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    pred = (predictions > threshold).astype(int)\n",
    "    false_negatives = (y_validate == 1) & (pred == 0)\n",
    "    false_positives = (y_validate == 0) & (pred == 1)\n",
    "    true_positives = (y_validate == 1) & (pred == 1)\n",
    "    new_row = pd.DataFrame({\n",
    "        'threshold': [threshold],\n",
    "        'false_negatives': [false_negatives.sum()],\n",
    "        'false_positives': [false_positives.sum()],\n",
    "        'true_positives': [true_positives.sum()]\n",
    "    })\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cost reduce, we want the lowest false negatives balanced with false positives and true positives, the best one for it is the threshold with value 0.1 that is almost the RMSE value. \n",
    "### Calculating the cost reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating if 25% of positives needed maintance trucks that is not sended to maintance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 53906.25\n"
     ]
    }
   ],
   "source": [
    "not_sended_trucks = y_validate.sum() *0.25\n",
    "sended_trucks = y_validate.sum() - not_sended_trucks\n",
    "full_cost_not_sended_trucks = not_sended_trucks * 500\n",
    "full_cost_sended_trucks = sended_trucks * 25\n",
    "total_cost = full_cost_not_sended_trucks + full_cost_sended_trucks\n",
    "\n",
    "print(f'Total cost: {total_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the cost of the previewed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = int(results[results['threshold'] == 0.1].drop('threshold', axis=1)['false_negatives'].astype(int))\n",
    "fp = int(results[results['threshold'] == 0.1].drop('threshold', axis=1)['false_positives'].astype(int))\n",
    "tp = int(results[results['threshold'] == 0.1].drop('threshold', axis=1)['true_positives'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted cost: 31500\n"
     ]
    }
   ],
   "source": [
    "full_predicted_cost_not_sended_trucks = fn * 500\n",
    "full_predicted_cost_sended_trucks = tp * 25\n",
    "full_predicted_cost_sended_trucks_with_no_need = fp * 10\n",
    "total_predicted_cost = full_predicted_cost_not_sended_trucks + full_predicted_cost_sended_trucks + full_predicted_cost_sended_trucks_with_no_need\n",
    "\n",
    "print(f'Total predicted cost: {total_predicted_cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total reduced cost with this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$22406 reduced dollars and  41% reduced cost\n"
     ]
    }
   ],
   "source": [
    "print(f'${int(total_cost - total_predicted_cost)} reduced dollars and ', f'{int((total_cost - total_predicted_cost) / total_cost * 100)}% reduced cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if 25% of the defected air system trucks is not sended correctly to maintance, the model could help reducing 41% of the fully cost.\n",
    "\n",
    "And as we saved the data pipeline and the best models, we could use it later to retrain the model with new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
